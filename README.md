## 1. 환경 설정 및 데이터 준비
- 환경 설정: 랜덤 시드 고정으로 재현성을 확보하고, GPU/CPU를 자동으로 선택
- 데이터셋: 손상된 이미지(damage_dir)와 원본 이미지(origin_dir) 쌍으로 구성된 데이터를 불러오기
- 이미지를 256x256 크기로 변환하고, 텐서화 및 정규화를 수행
- DataLoader를 사용해 배치 단위로 데이터를 불러오기
## 2. 모델 구성
- Generator (U-Net): U-Net 구조를 사용해 손상된 이미지를 복원
- 이미지를 압축(downsampling)하고 다시 확장(upsampling)하며, 중간 단계의 특징을 재사용
- Discriminator (PatchGAN): 복원된 이미지와 원본 이미지가 얼마나 비슷한지 판별
- PatchGAN은 이미지의 작은 패치 단위로 진위를 판단
## 3. 학습 과정
- 손실 함수: MSELoss-판별자가 복원된 이미지를 진짜처럼 보이게 하는 역할 (GAN 손실)
- L1Loss: 복원된 이미지와 원본 이미지 간의 픽셀 차이를 최소화 (픽셀 손실)
- 학습 루프: Generator는 손상된 이미지를 복원하고, 복원된 이미지가 원본처럼 보이도록 학습
- Discriminator는 복원된 이미지(가짜)와 원본 이미지(진짜)를 구분하는 법을 학습
- 두 네트워크를 번갈아 학습하면서 복원 성능과 판별 성능을 동시에 향상
## 4. 모델 저장
- 학습이 완료되면 Generator와 Discriminator의 가중치를 저장

## 점수: 0.4062429737
